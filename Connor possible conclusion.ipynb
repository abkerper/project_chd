{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN31oetLpgVv/SzLI00oLQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abkerper/project_chd/blob/main/Connor%20possible%20conclusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRMYZU81QLZ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Possible Conclusion for Project:"
      ],
      "metadata": {
        "id": "bIdFS0KnQL2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "When looking at the linear regressions that we completed for the determinants of Coronary Heart Disease, it became evident that the relationship between the disease and the variables included in the survey do have a correlation, however, the relationship between them are not purely linear. It was not until we included logarithmic adjustments and interaction terms that we were able to achieve an acceptable value for the correlation coefficient, R squared.\n",
        "\n",
        "Although this might mean that the regression that we were able to achieve is not perfect enough to use in a medical setting, it is still important to look at the coefficients that we discovered on each of the variables that we tested. Factors that had large positive coefficients are likely influential on the prevalence of CHD and therefore should be especially avoided when considering the risk factors of the disease. In these regressions, we can tell the direction of the variables since there are likely enough variables to appropriately fit the model, however the problem of heteroscedasticity does influence the interpretation of the coefficients. The implication of this could be overinflated values or instances of multicollinearity.\n",
        "\n",
        "Since the model we chose to build was a linear regression, it is important to consider the further effects of heteroskedasticity on our model. It is highly likely that the variance between the explanatory variables and our error term was not constant throughout the wide range of variables that we included in the model. Simply due to the nature of the variables tested and the plethora of other untested variables that could contribute to CHD, homoscedasticity was nearly impossible. However, since the R squared value is not impacted directly by homoscedasticity in the model, and the dependent variable included in each model is the same, the metric is still a valid comparison between the different regressions that we tested. In order to compare other metrics, we likely would have to calculate the heteroskedastic robust standard errors and coefficients.\n",
        "\n",
        "Other variables not included in the survey that would be interesting to investigate could be the prevalence of heart conditions in other family members/parents, external stressors, general diet and more specific drug use patterns, as well as certain medications (ex. Blood thinners) that are being used. Being able to have data on these values could help us build a more robust regression and achieve more effective outcomes for our linear model.  \n"
      ],
      "metadata": {
        "id": "Xdyh3n0tQQl4"
      }
    }
  ]
}